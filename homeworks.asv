%1.1
function gray_image = rgb_to_gray(input_image)
    % This function is supposed to convert a RGB-image to a grayscale image.
    % If the image is already a grayscale image directly return it.
    if length(size(input_image)) == 3
        rgb = double(input_image);
        gray_image = 0.299 * rgb(:, :, 1) + 0.587 * rgb(:, :, 2) + 0.114 * rgb(:, :, 3);
        gray_image = uint8(gray_image);
    else
        gray_image = input_image;
end

%1.2
function [Fx, Fy] = sobel_xy(input_image)
    % In this function you have to implement a Sobel filter 
    % that calculates the image gradient in x- and y- direction of a grayscale image.
    x = [1 0 -1; 2 0 -2; 1 0 -1];
    y = [1 2 1; 0 0 0; -1 -2 -1];
    
    Fx = conv2(input_image, x, 'same');
    Fy = conv2(input_image, y, 'same');
    
end

%1.3
function [segment_length, k, tau, do_plot] = harris_detector(input_image, varargin)
    % In this function you are going to implement a Harris detector that extracts features
    % from the input_image.

    %% Input parser
    parser = inputParser;
    addRequired(parser, 'input_image');
    addOptional(parser, 'segment_length', 15, @(x) isnumeric(x) && (x > 1) && rem(x,2) == 1);
    addOptional(parser, 'k', 0.05, @(x) isnumeric(x) && (x >= 0) && (x <= 1));
    addOptional(parser, 'tau', 1e6, @(x) isnumeric(x) && (x > 0));
    addOptional(parser, 'do_plot', false, @(x) islogical(x));
    parse(parser,input_image,varargin{:});
    
    segment_length = parser.Results.segment_length;
    k = parser.Results.k;
    tau = parser.Results.tau;
    do_plot = parser.Results.do_plot;
    
    features = {segment_length, k, tau, do_plot};
end

%1.4
function [Ix, Iy, w, G11, G22, G12] = harris_detector(input_image, varargin)
    % In this function you are going to implement a Harris detector that extracts features
    % from the input_image.
    
    %% Input parser from task 1.3
    % segment_length    size of the image segment
    % k                 weighting between corner- and edge-priority
    % tau               threshold value for detection of a corner
    % do_plot           image display variable
    input_parser
    
    %% Preparation for feature extraction
    % Check if it is a grayscale image
    if length(size(input_image)) ~= 2
        error("Image format has to be NxMx1")
    else
        gray = double(input_image);
    
    % Approximation of the image gradient
    [Ix, Iy] = sobel_xy(gray);
    
    % Weighting
    std_dev = segment_length/5;
    bound = segment_length/2 - 0.5;
    format = linspace(-bound, bound, segment_length);
    w = (1/sqrt(2*pi*(std_dev^2))) * exp(-(format.^2)/(2*std_dev));
    w = w/sum(w);

    % Harris Matrix G
    G11 = conv2((Ix.*Ix), w'*w, 'same');
    G22 = conv2((Iy.*Iy), w'*w, 'same');
    G12 = conv2((Ix.*Iy), w'*w, 'same');
end

%1.5
function [H, corners, features] = harris_detector(input_image, varargin)
    % In this function you are going to implement a Harris detector that extracts features
    % from the input_image.
    
    %% Input parser from task 1.3
    % segment_length    size of the image segment
    % k                 weighting between corner- and edge-priority
    % tau               threshold value for detection of a corner
    % do_plot           image display variable
    input_parser

    %% Preparation for feature extraction from task 1.4
    % Ix, Iy            image gradient in x- and y-direction
    % w                 weighting vector
    % G11, G12, G22     entries of the Harris matrix
    image_preprocessing
    
    %% Feature extraction with the Harris measurement
    dimension = size(G11);
    H = zeros(dimension);
    for i=(1:dimension(1))
        for j=(1:dimension(2))
            g = [G11(i,j) G12(i,j); G12(i,j) G22(i,j)];
            H(i,j) = det(g) - (k*(trace(g)^2));
        end
    end
    
    corners = H;
    threshold = ceil(segment_length/2);
    corners(1:threshold,:) = 0;
    corners(:,1:threshold) = 0;
    corners(dimension(1)-threshold:dimension(1),:) = 0;
    corners(:,dimension(2)-threshold:dimension(2)) = 0;
    corners(corners<tau) = 0;
    
    [row, col] = find(corners);
    features = [col row]';
end

%1.6
function features = harris_detector(input_image, varargin)
    % In this function you are going to implement a Harris detector that extracts features
    % from the input_image.
    
    %% Input parser from task 1.3
    % segment_length    size of the image segment
    % k                 weighting between corner- and edge-priority
    % tau               threshold value for detection of a corner
    % do_plot           image display variable
    input_parser

    %% Preparation for feature extraction from task 1.4
    % Ix, Iy            image gradient in x- and y-direction
    % w                 weighting vector
    % G11, G12, G22     entries of the Harris matrix
    image_preprocessing
    
    %% Feature extraction with the Harris measurement from task 1.5
    % features          detected features
    % corners           matrix containing the value of the Harris measurement for each pixel
    harris_measurement
    
    %% Plot
    if do_plot
        figure
        imshow(input_image)
        hold on
        plot(features(1,:), features(2,:), 'LineStyle','none','Marker','x','MarkerEdgeColor','y')
end

%1.7
function [min_dist, tile_size, N] = harris_detector(input_image, varargin)
    % In this function you are going to implement a Harris detector that extracts features
    % from the input_image.
    
    %% Input parser
    parser = inputParser;
    addRequired(parser, 'input_image');
    addOptional(parser, 'segment_length', 15, @(x) isnumeric(x) && (x > 1) && rem(x,2) == 1);
    addOptional(parser, 'k', 0.05, @(x) isnumeric(x) && (x >= 0) && (x <= 1));
    addOptional(parser, 'tau', 1e6, @(x) isnumeric(x) && (x > 0));
    addOptional(parser, 'do_plot', false, @(x) islogical(x));
    addOptional(parser, 'min_dist', 20, @(x) isnumeric(x) && (x >= 1));
    addOptional(parser, 'tile_size', 200, @(x) isnumeric(x));
    addOptional(parser, 'N', 5, @(x) isnumeric(x) && (x >= 1));
    parse(parser,input_image,varargin{:});
    
    segment_length = parser.Results.segment_length;
    k = parser.Results.k;
    tau = parser.Results.tau;
    do_plot = parser.Results.do_plot;
    min_dist = parser.Results.min_dist;
    tile_size = parser.Results.tile_size;
    N = parser.Results.N;
    
    if (length(tile_size) == 1) 
        tile_size = [tile_size, tile_size];
    
end

%1.8
function Cake = cake(min_dist)
    % The cake function creates a "cake matrix" that contains a circular set-up of zeros
    % and fills the rest of the matrix with ones. 
    % This function can be used to eliminate all potential features around a stronger feature
    % that don't meet the minimal distance to this respective feature.
    Cake = logical(zeros((2*min_dist) + 1));
    mid = min_dist + 1;
    for i=(1:length(Cake))
        for j=(1:length(Cake))
            diff_i = abs(i - mid);
            diff_j = abs(j - mid);
            if ((diff_i^2+diff_j^2) <= min_dist^2)
                Cake(i,j) = false;
            else
                Cake(i,j) = true;
            end
        end
    end
end

%1.9
function [corners, sorted_index] = harris_detector(input_image, varargin)
    % In this function you are going to implement a Harris detector that extracts features
    % from the input_image.
    
    %% Input parser from task 1.7
    % segment_length    size of the image segment
    % k                 weighting between corner- and edge-priority
    % tau               threshold value for detection of a corner
    % do_plot           image display variable
    % min_dist          minimal distance of two features in pixels
    % tile_size         size of the tiles
    % N                 maximal number of features per tile
    input_parser_new

    %% Preparation for feature extraction from task 1.4
    % Ix, Iy            image gradient in x- and y-direction
    % w                 weighting vector
    % G11, G12, G22     entries of the Harris matrix
    image_preprocessing
    
    %% Feature extraction with the Harris measurement from task 1.5
    % corners           matrix containing the value of the Harris measurement for each pixel         
    % features          detected features
    harris_measurement
    
    %% Feature preparation
    dimension = size(corners);
    corners = [zeros(dimension(1), min_dist), corners, zeros(dimension(1), min_dist)];
    dimension = size(corners);
    corners = [zeros(min_dist, dimension(2)); corners; zeros(min_dist, dimension(2))];
    
    corners_2 = reshape(corners, [], 1);
    [ranked, index] = sort(corners_2, 'descend');
    ranked = ranked(ranked > 0);
    sorted_index = index(1:length(ranked));
end

%1.10
function [acc_array, features] = harris_detector(input_image, varargin)
    % In this function you are going to implement a Harris detector that extracts features
    % from the input_image.
    
    %% Input parser from task 1.7
    % segment_length    size of the image segment
    % k                 weighting between corner- and edge-priority
    % tau               threshold value for detection of a corner
    % do_plot           image display variable
    % min_dist          minimal distance of two features in pixels
    % tile_size         size of the tiles
    % N                 maximal number of features per tile
    input_parser_new

    %% Preparation for feature extraction from task 1.4
    % Ix, Iy            image gradient in x- and y-direction
    % w                 weighting vector
    % G11, G12, G22     entries of the Harris matrix
    image_preprocessing
    
    %% Feature extraction with the Harris measurement from task 1.5
    % corners           matrix containing the value of the Harris measurement for each pixel         
    harris_measurement
    
    %% Feature preparation from task 1.9
    %corners            Harris measurement for each pixel respecting the minimal distance
    %sorted_index       Index list of features sorted descending by thier strength
    feature_preprocessing
    
    %% Accumulator array
    dimension = size(corners);
    acc_dim_y = floor(dimension(1)/tile_size(1));
    acc_dim_x = floor(dimension(2)/tile_size(2));
    accumulation = zeros(acc_dim_y, acc_dim_x);
    
    for i = (1:length(sorted_index))
        residual = mod(sorted_index(i), dimension(1));
        if residual == 0
            pos_y = dimension(1);
            pos_x = sorted_index(i)/dimension(1);
        else
            pos_x = floor(sorted_index(i)/dimension(1)) + 1;
            pos_y = residual;
        end
        
        bound_y_low = 0;
        bound_y_up = 0;
        bound_x_low = 0;
        bound_x_up = 0;
        
        for j = (1:acc_dim_y)
            for k=(1:acc_dim_x)
                bound_y_low = tile_size(1) * (j-1);
                bound_y_up = tile_size(1) * j;
                bound_x_low = tile_size(2) * (k-1);
                bound_x_up = tile_size(2) * k;
                if (pos_y > bound_y_low) && (pos_y <= bound_y_up)
                    if (pos_x > bound_x_low) && (pos_x <= bound_x_up)
                        accumulation(j,k) = accumulation(j,k) + 1;
                    end
                end
            end
        end
    end
    
    acc_temp = reshape(accumulation, [], 1);
    final_length = 0;
    for i = (1:length(acc_temp))
        tile_space = min(N, acc_temp(i));
        final_length = final_length + tile_space;
    end
        
    acc_array = zeros(acc_dim_y,acc_dim_x);
    features = zeros(2,final_length);
end

%1.11
function features = harris_detector(input_image, varargin)
    % In this function you are going to implement a Harris detector that extracts features
    % from the input_image.
    
    %% Input parser from task 1.7
    % segment_length    size of the image segment
    % k                 weighting between corner- and edge-priority
    % tau               threshold value for detection of a corner
    % do_plot           image display variable
    % min_dist          minimal distance of two features in pixels
    % tile_size         size of the tiles
    % N                 maximal number of features per tile
    input_parser_new

    %% Preparation for feature extraction from task 1.4
    % Ix, Iy            image gradient in x- and y-direction
    % w                 weighting vector
    % G11, G12, G22     entries of the Harris matrix
    image_preprocessing
    
    %% Feature extraction with the Harris measurement from task 1.5
    % corners           matrix containing the value of the Harris measurement for each pixel               
    harris_measurement
    
    %% Feature preparation from task 1.9
    % sorted_index      sorted indices of features in decreasing order of feature strength
    feature_preprocessing
    
    %% Accumulator array from task 1.10
    % acc_array         accumulator array which counts the features per tile
    % features          empty array for storing the final features
    accumulator_array
    
    %% Feature detection with minimal distance and maximal number of features per tile
    size_corners = size(corners);
    [acc_dim_y, acc_dim_x] = size(acc_array);
    addIndex = 0;
    dist_mask = cake(min_dist);
    for i = (1:length(sorted_index))
        
        [current_pos_y, current_pos_x] = ind2sub(size_corners, sorted_index(i));
        current_pos = [current_pos_y, current_pos_x];
        if (corners(current_pos(1), current_pos(2)) ~=0)
            
            corners((current_pos(1) - min_dist):(current_pos(1) + min_dist), (current_pos(2) - min_dist):(current_pos(2) + min_dist)) = corners((current_pos(1) - min_dist):(current_pos(1) + min_dist), (current_pos(2) - min_dist):(current_pos(2) + min_dist)) .* dist_mask;
            
            img_pos = current_pos - (ones(1,2) * min_dist);
            for j=(1:acc_dim_y)
                for k=(1:acc_dim_x)
                    bound_y_low = tile_size(1) * (j-1);
                    bound_y_up = tile_size(1) * j;
                    bound_x_low = tile_size(2) * (k-1);
                    bound_x_up = tile_size(2) * k;
                    if (img_pos(1) > bound_y_low) && (img_pos(1) <= bound_y_up)
                        if (img_pos(2) > bound_x_low) && (img_pos(2) <= bound_x_up)
                            if (acc_array(j,k) < N)
                                acc_array(j,k) = acc_array(j,k) + 1;
                                addIndex = addIndex + 1;
                                features(:, addIndex) = [img_pos(2); img_pos(1)];
                             end
                        end
                    end
                end
            end
        end
    end
    
    features = features(:, 1:addIndex);
    
    % Plot Routine
    plotting
end

%2.1
function [window_length, min_corr, do_plot, Im1, Im2] = point_correspondence(I1, I2, Ftp1, Ftp2, varargin)
    % In this function you are going to compare the extracted features of a stereo recording
    % with NCC to determine corresponding image points.
    
    %% Input parser
    parser = inputParser;
    addOptional(parser, 'window_length', 25, @(x) isnumeric(x) && (x > 1) && rem(x,2) == 1);
    addOptional(parser, 'min_corr', 0.95, @(x) isnumeric(x) && ((x > 0) && (x < 1)));
    addOptional(parser, 'do_plot', false, @(x) islogical(x));
    parse(parser,varargin{:});
    
    Im1 = double(I1);
    Im2 = double(I2);
    window_length = parser.Results.window_length;
    min_corr = parser.Results.min_corr;
    do_plot = parser.Results.do_plot;
end

%2.2
function [no_pts1, no_pts2, Ftp1, Ftp2] = point_correspondence(I1, I2, Ftp1, Ftp2, varargin)
    % In this function you are going to compare the extracted features of a stereo recording
    % with NCC to determine corresponding image points.
    
    %% Input parser from task 2.1
    % window_length     side length of quadratic window
    % min_corr          threshold for the correlation of two features
    % do_plot           image display variable
    % Im1, Im2          input images (double)
    input_parser
    
    %% Feature preparation
    buffer = zeros(size(Ftp1));
    adder = 0;
    for i = (1:length(Ftp1))
        current = Ftp1(:, i);
        if (included(size(Im1), window_length, [current(2), current(1)]))
            adder = adder + 1;
            buffer(:, adder) = current;
        end
    end
    Ftp1 = buffer(:, 1:adder);
    no_pts1 = adder;
    
    buffer = zeros(size(Ftp2));
    adder = 0;
    for i = (1:length(Ftp2))
        current = Ftp2(:,i);
        if (included(size(Im1), window_length, [current(2),current(1)]))
            adder = adder + 1;
            buffer(:, adder) = current;
        end
    end
    Ftp2 = buffer(:, 1:adder);
    no_pts2 = adder;
end

function included_return = included(img_dimension, window_length, current)
    included_return = false;
    max_distance = (window_length - 1)/2;
    if ((current(1) - max_distance) > 0) && ((current(1) + max_distance) <= img_dimension(1))
        if ((current(2) - max_distance) > 0) && ((current(2) + max_distance) <= img_dimension(2))
            included_return = true;
        end
    end
end

%2.3
function [Mat_feat_1, Mat_feat_2] = point_correspondence(I1, I2, Ftp1, Ftp2, varargin)
    % In this function you are going to compare the extracted features of a stereo recording
    % with NCC to determine corresponding image points.
    
    %% Input parser from task 2.1
    % window_length         side length of quadratic window
    % min_corr              threshold for the correlation of two features
    % do_plot               image display variable
    % Im1, Im2              input images (double)
    input_parser
    
    %% Feature preparation from task 2.2
    % no_pts1, no_pts 2     number of features remaining in each image
    % Ftp1, Ftp2            preprocessed features
    feature_preprocessing
    
    %% Normalization
    Mat_feat_1 = [];
    for i=(1:no_pts1)
        window = extract(Im1, Ftp1(:, i), window_length);
        window = reshape(window, [], 1);
        mue = mean(window);
        sigma = std(window);
        window = window - (ones(size(window)) * mue);
        window = window .* (1/sigma);
        Mat_feat_1 = [Mat_feat_1, window];
    end
    
    Mat_feat_2 = [];
    for i=(1:no_pts2)
        window = extract(Im2, Ftp2(:, i), window_length);
        window = reshape(window, [], 1);
        mue = mean(window);
        sigma = std(window);
        window = window - (ones(size(window)) * mue);
        window = window .* (1/sigma);
        Mat_feat_2 = [Mat_feat_2, window];
    end    
end

function window = extract(I, current, window_length)
    offset = (window_length - 1)/2;
    window = I((current(2) - offset):(current(2) + offset), (current(1) - offset):(current(1) + offset));
end

%2.4
function [NCC_matrix, sorted_index] = point_correspondence(I1, I2, Ftp1, Ftp2, varargin)
    % In this function you are going to compare the extracted features of a stereo recording
    % with NCC to determine corresponding image points.
    
    %% Input parser from task 2.1
    % window_length         side length of quadratic window
    % min_corr              threshold for the correlation of two features
    % do_plot               image display variable
    % Im1, Im2              input images (double)
    input_parser
    
    %% Feature preparation from task 2.2
    % no_pts1, no_pts 2     number of features remaining in each image
    % Ftp1, Ftp2            preprocessed features
    feature_preprocessing
    
    %% Normalization from task 2.3
    % Mat_feat_1            normalized windows in image 1
    % Mat_feat_2            normalized windows in image 2
    window_normalization
    
    %% NCC calculations
    NCC_matrix = zeros(no_pts2, no_pts1);
    n = window_length^2;
    
    for i = (1:no_pts1)
        for j = (1:no_pts2)
            NCC_matrix(j, i) = (1/(n - 1)) * (Mat_feat_2(:, j)' * Mat_feat_1(:, i));
        end
    end
    
    NCC_matrix(NCC_matrix < min_corr) = 0;
    NCC_matrix_column = reshape(NCC_matrix, [], 1);
    [correlation_ranked, index] = sort(NCC_matrix_column, 'descend');
    correlation_ranked = correlation_ranked(correlation_ranked > 0);
    sorted_index = index(1:length(correlation_ranked));   
end

%2.5
function cor = point_correspondence(I1, I2, Ftp1, Ftp2, varargin)
    % In this function you are going to compare the extracted features of a stereo recording
    % with NCC to determine corresponding image points.
    
    %% Input parser from task 2.1
    % window_length         side length of quadratic window
    % min_corr              threshold for the correlation of two features
    % do_plot               image display variable
    % Im1, Im2              input images (double)
    input_parser
    
    %% Feature preparation from task 2.2
    % no_pts1, no_pts 2     number of features remaining in each image
    % Ftp1, Ftp2            preprocessed features
    feature_preprocessing
    
    %% Normalization from task 2.3
    % Mat_feat_1            normalized windows in image 1
    % Mat_feat_2            normalized windows in image 2
    window_normalization
    
    %% NCC from task 2.4
    % NCC_matrix            matrix containing the correlation between the image points
    % sorted_index          sorted indices of NCC_matrix entries in decreasing order of intensity
    ncc_calculation
    
    %% Correspondeces
    cor = [];
    for i = (1:length(sorted_index))
        [mat_pos_y, mat_pos_x] = ind2sub(size(NCC_matrix), sorted_index(i));
        if (NCC_matrix(mat_pos_y, mat_pos_x) > 0)
            column1 = Ftp1(:,mat_pos_x);
            column2 = Ftp2(:,mat_pos_y);
            cor = [cor, [column1; column2]];
            NCC_matrix(:,mat_pos_x) = 0;
        end
    end 
end

%2.6
function cor = point_correspondence(I1, I2, Ftp1, Ftp2, varargin)
    % In this function you are going to compare the extracted features of a stereo recording
    % with NCC to determine corresponding image points.
    
    %% Input parser from task 2.1
    % window_length         side length of quadratic window
    % min_corr              threshold for the correlation of two features
    % do_plot               image display variable
    % Im1, Im2              input images (double)
    input_parser
    
    %% Feature preparation from task 2.2
    % no_pts1, no_pts 2     number of features remaining in each image
    % Ftp1, Ftp2            preprocessed features
    feature_preprocessing
    
    %% Normalization from task 2.3
    % Mat_feat_1            normalized windows in image 1
    % Mat_feat_2            normalized windows in image 2
    window_normalization
    
    %% NCC from task 2.4
    % NCC_matrix            matrix containing the correlation between the image points
    % sorted_index          sorted indices of NCC_matrix entries in decreasing order of intensity
    ncc_calculation
    
    %% Correspondeces from task 2.5
    % cor                   matrix containing all corresponding image points
    correspondence
    
    %% Visualize the correspoinding image point pairs
    if (do_plot == true)
        handle = imshow(I1);
        set(handle, 'AlphaData', ones(size(I1)) * 0.5);
        hold on
        handle2 = imshow(I2);
        set(handle2, 'AlphaData', ones(size(I1)) * 0.5);
        plot(cor(1,:), cor(2,:), 'LineStyle','none','Marker','x','MarkerEdgeColor','r');
        plot(cor(3,:), cor(4,:), 'LineStyle','none','Marker','x','MarkerEdgeColor','b');
        for i = (1:length(cor))
            plot([cor(1, i), cor(3, i)], [cor(2, i), cor(4, i)],'y');
        end
    end
end

%3.1
function [x1, x2, A, V] = epa(correspondences, K)
    % Depending on whether a calibrating matrix 'K' is given,
    % this function calculates either the essential or the fundamental matrix
    % with the eight-point algorithm.
    if (exist('K') == 1)
        x1 = correspondences(1:2,:);
        x2 = correspondences(3:4,:);
        x1 = [x1; ones(1, length(correspondences))];
        x2 = [x2; ones(1, length(correspondences))];
        x1 = inv(K) * x1;
        x2 = inv(K) * x2;
    else
        x1 = correspondences(1:2,:);
        x2 = correspondences(3:4,:);
        x1 = [x1; ones(1, length(correspondences))];
        x2 = [x2; ones(1, length(correspondences))];
    end
    
    A = [];
    for i = (1:length(x1))
        a = kron(x1(:, i), x2(:, i));
        A = [A; a'];
    end
    [U,S,V] = svd(A);
end

%3.2
